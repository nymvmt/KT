{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr9ik55TAtDB",
        "outputId": "6e3cd7fb-39ca-4755-f14b-157eb7ccd9a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (0.3.21)\n",
            "Requirement already satisfied: langchain_community in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (0.3.20)\n",
            "Requirement already satisfied: langchain_openai in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (0.3.1)\n",
            "Requirement already satisfied: pypdf in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (5.4.0)\n",
            "Requirement already satisfied: faiss-cpu in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (1.10.0)\n",
            "Requirement already satisfied: gradio in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (5.23.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (0.3.49)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (0.3.19)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain_community) (3.11.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain_community) (2.8.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain_openai) (1.75.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (2.2.3)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydub in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (0.11.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (0.46.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio-client==1.8.0->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.13.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain_community langchain_openai pypdf faiss-cpu gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cM8Fd1ZApIC"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = userdata.get('openai-api')\n",
        "TAVILY_API_KEY = userdata.get('travily-api')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install langchain gradio openai tavily-python pypdf faiss-cpu\n",
        "# coding QA Expert Chatbot using langchain and gradio as web UI. use PDF RAG with faiss vector DB to save, retrieve the chunk documents from the PDF. if run this chatbot, read the PDF files from ./files folder, splite them into chunks, save them to faiss as vector database. after that, create LLM using openai and create langchain prompt template, tools with web search using Tavily. create agents with them including the previous dialog memory. this UI using gradio is simliar to ChatBot.\n",
        "import os, re\n",
        "import glob\n",
        "import gradio as gr\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.tools.tavily_search import TavilySearchResults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. 설정\n",
        "VECTOR_DB_PATH = './faiss_index'\n",
        "FILES_DIRECTORY = './files'\n",
        "CHUNK_SIZE = 2000\n",
        "CHUNK_OVERLAP = 300\n",
        "\n",
        "# OpenAI 설정\n",
        "llm_model = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. PDF 파일 로드 및 벡터화\n",
        "def load_and_split_pdfs(files_directory):\n",
        "\tpdf_files = glob.glob(os.path.join(files_directory, '*.pdf'))\n",
        "\tdocuments = []\n",
        "\tfor file in pdf_files:\n",
        "\t\tloader = PyPDFLoader(file)\n",
        "\t\tdocuments.extend(loader.load())\n",
        "\tsplitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
        "\tsplit_documents = splitter.split_documents(documents)\n",
        "\tfor i, doc in enumerate(split_documents):\n",
        "\t\tprint(f\"Document {i}: {doc.page_content[:100]}...\")  # Print the first 100 characters of each split document\n",
        "\treturn splitter.split_documents(documents)\n",
        "\n",
        "# 3. FAISS 벡터DB 저장\n",
        "def save_to_faiss(documents):\n",
        "\tvectordb = FAISS.from_documents(documents, OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY))\n",
        "\tvectordb.save_local(VECTOR_DB_PATH)\n",
        "\tprint(f\"FAISS vector database saved to {VECTOR_DB_PATH}\")\n",
        "\treturn vectordb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. RAG Retrieval QA 체인 생성\n",
        "def create_retrieval_qa(vectordb):\n",
        "\tretriever = vectordb.as_retriever(search_type=\"mmr\", search_kwargs={'k': 3, 'lambda_mult': 0.25})\n",
        "\tqa_chain = RetrievalQA.from_chain_type(\n",
        "\t\tllm=llm_model,\n",
        "\t\tretriever=retriever,\n",
        "\t\tchain_type=\"stuff\"\n",
        "\t)\n",
        "\treturn qa_chain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Common agent Types:\n",
        "\n",
        "zero-shot-react-description:\n",
        "\tUses the ReAct (Reasoning + Acting) framework.\n",
        "\tSelects tools and generates responses based on tool descriptions.\n",
        "\tBest for scenarios where the agent needs to reason and act without prior context.\n",
        "\n",
        "chat-zero-shot-react-description:\n",
        "\tSimilar to zero-shot-react-description, but optimized for chat-based interactions.\n",
        "\tUseful for conversational agents.\n",
        "\n",
        "chat-conversational-react-description:\n",
        "\tDesigned for conversational agents with memory.\n",
        "\tKeeps track of the conversation history to provide context-aware responses.\n",
        "\tThis is the agent type used in your code.\n",
        "\n",
        "self-ask-with-search:\n",
        "\tDesigned for agents that need to ask clarifying questions before answering.\n",
        "\tOften used with search tools.\n",
        "\n",
        "react-docstore:\n",
        "\tOptimized for retrieving and reasoning over documents in a docstore.\n",
        "\tUseful for document-based question answering.\n",
        "\n",
        "conversational-react-description:\n",
        "\tSimilar to chat-conversational-react-description, but without explicit chat optimizations.\n",
        "\tIncludes memory for context-aware responses.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. LangChain Agent 생성\n",
        "def create_agent(qa_chain):\n",
        "\ttools = [\n",
        "\t\tTool(\n",
        "\t\t\tname=\"Expert PDF File QA\",\n",
        "\t\t\tfunc=qa_chain.run,\n",
        "\t\t\tdescription=\"질문에 대해 PDF 문서에서 답을 찾습니다.\"\n",
        "\t\t),\n",
        "\t\tTavilySearchResults(max_results=5, tavily_api_key=TAVILY_API_KEY)\n",
        "\t]\n",
        "\n",
        "\t'''\n",
        "\tprompt = PromptTemplate(\n",
        "\t\tinput_variables=[\"input\", \"chat_history\"],\n",
        "\t\ttemplate=\"\"\"\n",
        "너는 친절한 코딩 Q&A 봇입니다. 지금까지의 대화는 다음과 같습니다:\n",
        "{chat_history}\n",
        "\n",
        "사용자의 질문:\n",
        "{input}\n",
        "\n",
        "적절한 도구를 사용해서 답하세요.\n",
        "\t\t\"\"\"\n",
        "\t)\n",
        "\t'''\n",
        "\n",
        "\tprompt = PromptTemplate(\n",
        "\t\tinput_variables=[\"input\", \"chat_history\"],\n",
        "\t\ttemplate=\"\"\"너는 친절하고 전문적인 코딩 Q&A 어시스턴트이다.\n",
        "\n",
        "주어진 대화 내용을 참고하여 사용자의 질문에 대해 간결하고 명확한 답변을 작성하라.\n",
        "\n",
        "- 오직 답변 내용만 작성하라.\n",
        "- 서론, 결론, 불필요한 인삿말 없이, 질문에 대한 정확한 설명이나 해결책만 제공하라.\n",
        "\n",
        "지금까지의 대화:\n",
        "{chat_history}\n",
        "\n",
        "사용자의 질문:\n",
        "{input}\n",
        "\n",
        "답변:\n",
        "\"\"\"\n",
        "\t)\n",
        "\n",
        "\n",
        "\tmemory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "\tagent = initialize_agent(\n",
        "\t\ttools=tools,\n",
        "\t\tllm=llm_model,\n",
        "\t\tagent=\"chat-conversational-react-description\",\n",
        "\t\tmemory=memory,\n",
        "\t\tverbose=True,\n",
        "\t\tagent_kwargs={\"prompt\": prompt},\n",
        "\t\thandle_parsing_errors=False # not working. \n",
        "\t)\n",
        "\treturn agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_action_input(text):\n",
        "\t# \"action_input\": \"...\" 패턴을 정규식으로 추출\n",
        "\tpattern = r'\"action_input\"\\s*:\\s*\"([^\"]+)\"'\n",
        "\tmatch = re.search(pattern, text, re.DOTALL)\n",
        "\tif match:\n",
        "\t\treturn match.group(1)  # 캡처한 \"...\" 안의 내용 리턴\n",
        "\treturn None  \n",
        "\n",
        "def clean_action_input_with_llm(text):\n",
        "\tprompt = f\"\"\"\n",
        "다음 텍스트에서 \"action_input\" 값에 해당하는 부분만 정확히 추출해줘.\n",
        "그 외의 모든 내용은 제거해. \n",
        "\n",
        "텍스트:\n",
        "{text}\n",
        "\n",
        "오직 \"action_input\" 안의 내용만 깔끔히 리턴해줘. 추가 설명 없이.\n",
        "\t\"\"\"\n",
        "\n",
        "\tresponse = llm_model.invoke(prompt)\n",
        "\treturn response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 초기화 과정\n",
        "if not os.path.exists(VECTOR_DB_PATH):\n",
        "    os.makedirs(VECTOR_DB_PATH, exist_ok=True)\n",
        "    docs = load_and_split_pdfs(FILES_DIRECTORY)\n",
        "    save_to_faiss(docs)\n",
        "\n",
        "vectordb = FAISS.load_local(VECTOR_DB_PATH, OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY), allow_dangerous_deserialization=True)\n",
        "qa_chain = create_retrieval_qa(vectordb)\n",
        "agent = create_agent(qa_chain)\n",
        "\n",
        "def chatbot_interface(user_input, history):\n",
        "    try:\n",
        "        response = agent.run(user_input)\n",
        "        history = history + [(user_input, response)]\n",
        "    except Exception as e:\n",
        "        msg = f\"Error: {str(e)}\"\n",
        "        print(msg)\n",
        "\n",
        "        response = extract_action_input(str(e))\n",
        "        if response == None:\n",
        "            response = clean_action_input_with_llm(str(e))\n",
        "        history = history + [(user_input, response)]\n",
        "\n",
        "    return history, history\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"Coding QA Expert Chatbot (PDF + Web Search)\")\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox(placeholder=\"질문을 입력하세요...\") # 1) in pdf, what is b2gm? 2) i'm tom, developer. 3) who is tom\n",
        "\n",
        "    clear = gr.Button(\"초기화\")\n",
        "\n",
        "    state = gr.State([])\n",
        "    msg.submit(chatbot_interface, [msg, state], [chatbot, state])\n",
        "    clear.click(lambda: ([], []), None, [chatbot, state])\n",
        "\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv_lmm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
