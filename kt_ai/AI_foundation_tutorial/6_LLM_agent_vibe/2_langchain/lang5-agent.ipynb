{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzJURCUDJWcg",
        "outputId": "cf9c7dfb-1033-4ae4-a08a-ad942ade3935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (0.3.21)\n",
            "Requirement already satisfied: openai in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (1.75.0)\n",
            "Requirement already satisfied: wikipedia in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (1.4.0)\n",
            "Requirement already satisfied: langchain-community in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (0.3.20)\n",
            "Requirement already satisfied: numexpr in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (2.10.2)\n",
            "Requirement already satisfied: httpx==0.27.2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (0.27.2)\n",
            "Requirement already satisfied: anyio in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from httpx==0.27.2) (4.9.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from httpx==0.27.2) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from httpx==0.27.2) (1.0.7)\n",
            "Requirement already satisfied: idna in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from httpx==0.27.2) (3.10)\n",
            "Requirement already satisfied: sniffio in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from httpx==0.27.2) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from httpcore==1.*->httpx==0.27.2) (0.14.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (0.3.49)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (0.3.19)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from wikipedia) (4.13.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain-community) (3.11.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain-community) (2.8.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mac\\.conda\\envs\\venv_lmm\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai wikipedia langchain-community numexpr \"httpx==0.27.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao35vlRiJjSs",
        "outputId": "e6cc209a-e442-4d54-c7ef-8d779b2e1b07"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key_here\" \n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.1, max_tokens=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RXcTlqftJjVt"
      },
      "outputs": [],
      "source": [
        "# zeroshot ReAct agent with Wikipedia and LLM Math tools\n",
        "from langchain.agents import initialize_agent, load_tools, AgentType\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5HtA94OKCu_",
        "outputId": "dd4a3a03-5809-4782-baff-410190f343d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m여행하기 좋은 시기는 지역과 개인의 취향에 따라 다를 수 있습니다. 일반적으로 날씨가 온화하고 비가 적은 시기가 여행하기에 좋습니다. 예를 들어, 많은 사람들이 봄(4월~6월)과 가을(9월~11월)을 여행하기 좋은 시기로 꼽습니다. 이 시기에는 날씨가 쾌적하고 자연 경관도 아름답기 때문입니다. 하지만 특정 지역이나 활동에 따라 선호하는 시기가 다를 수 있으니, 여행 목적지의 기후와 개인의 취향을 고려하여 계획하는 것이 좋습니다. \n",
            "\n",
            "Final Answer: 일반적으로 여행하기 좋은 시기는 봄(4월~6월)과 가을(9월~11월)입니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': '요즘 여행가기 좋은 날은 몇월이야?',\n",
              " 'output': '일반적으로 여행하기 좋은 시기는 봄(4월~6월)과 가을(9월~11월)입니다.'}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# initialize the agent with the tools and LLM\n",
        "# ZERO_SHOT_REACT_DESCRIPTION \n",
        "agent = initialize_agent(tools , llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, handle_parsing_errors=True, verbose=True) \n",
        "agent.invoke(\"요즘 여행가기 좋은 날은 몇월이야?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCNJzr7yK8IX",
        "outputId": "438cd3ea-9068-49a6-ddb8-79fcda5db614"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Geoffrey Hinton is a renowned computer scientist known for his work on artificial neural networks and deep learning. He has made significant contributions to the field of artificial intelligence and is often referred to as one of the \"godfathers of AI.\" Hinton was born on December 6, 1947. Given that today is May 1, 2025, he would be 77 years old.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'Who is Geoffrey Hinton and how old is he? In addition, today is 2025-05-01.',\n",
              " 'chat_history': '',\n",
              " 'output': 'Geoffrey Hinton is a renowned computer scientist known for his work on artificial neural networks and deep learning. He has made significant contributions to the field of artificial intelligence and is often referred to as one of the \"godfathers of AI.\" Hinton was born on December 6, 1947. Given that today is May 1, 2025, he would be 77 years old.'}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Conversational ReAct\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "tools = load_tools([\"llm-math\"],  llm=llm)                      # llm-math 도구만 사용\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")    # 대화 기록 메모리 키 이름 설정\n",
        "conversational_agent = initialize_agent(\n",
        "    agent='conversational-react-description',\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,     # 디버깅 정보 출력\n",
        "    max_iterations=3, # 에이전트 질문 해결 위한 최대 반복 횟수\n",
        "    memory=memory,)\n",
        "conversational_agent.invoke(\"Who is Geoffrey Hinton and how old is he? In addition, today is 2025-05-01.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rhNVBvik6c79"
      },
      "outputs": [],
      "source": [
        "# Self Ask With Search Agent\n",
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_self_ask_with_search_agent\n",
        "from langchain_community.tools.tavily_search import TavilyAnswer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oKjwoSm36xz0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"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\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0OxjoRy6c_H",
        "outputId": "877b24d2-5bc3-4517-e501-b080f41e347f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\MAC\\.conda\\envs\\venv_lmm\\Lib\\site-packages\\langsmith\\client.py:277: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: How old was Muhammad Ali when he died?\n",
            "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
            "Follow up: How old was Alan Turing when he died?\n",
            "Intermediate answer: Alan Turing was 41 years old when he died.\n",
            "So the final answer is: Muhammad Ali\n",
            "\n",
            "Question: When was the founder of craigslist born?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the founder of craigslist?\n",
            "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
            "Follow up: When was Craig Newmark born?\n",
            "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
            "So the final answer is: December 6, 1952\n",
            "\n",
            "Question: Who was the maternal grandfather of George Washington?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the mother of George Washington?\n",
            "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
            "Follow up: Who was the father of Mary Ball Washington?\n",
            "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
            "So the final answer is: Joseph Ball\n",
            "\n",
            "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who is the director of Jaws?\n",
            "Intermediate answer: The director of Jaws is Steven Spielberg.\n",
            "Follow up: Where is Steven Spielberg from?\n",
            "Intermediate answer: The United States.\n",
            "Follow up: Who is the director of Casino Royale?\n",
            "Intermediate answer: The director of Casino Royale is Martin Campbell.\n",
            "Follow up: Where is Martin Campbell from?\n",
            "Intermediate answer: New Zealand.\n",
            "So the final answer is: No\n",
            "\n",
            "Question: {input}\n",
            "Are followup questions needed here:{agent_scratchpad}\n"
          ]
        }
      ],
      "source": [
        "tools = [TavilyAnswer(max_results=5, name=\"Intermediate Answer\")]   # TavilyAnswer 도구 사용\n",
        "prompt = hub.pull(\"hwchase17/self-ask-with-search\")                 # \"Self Ask With Search\" 프롬프트를 가져옴\n",
        "print(prompt.template) # 프롬프트 템플릿 출력\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': 'Who lived longer, Muhammad Ali or Alan Turing?',\n",
              " 'output': 'Agent stopped due to iteration limit or time limit.'}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent = create_self_ask_with_search_agent(llm, tools, prompt) # \"Self Ask With Search\" 에이전트 생성\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, handle_parsing_errors=True, max_iterations=5, max_execution_time=10) # AgentExecutor 로 에이전트, 도구, 파싱 에러 처리 설정\n",
        "agent_executor.invoke({\"input\": \"Who lived longer, Muhammad Ali or Alan Turing?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY_iuYwa7NIp",
        "outputId": "3bc5513a-fe63-4675-f338-9e60140ca0f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\MAC\\AppData\\Local\\Temp\\ipykernel_10244\\1283922457.py:6: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  docstore=DocstoreExplorer(Wikipedia())\n"
          ]
        }
      ],
      "source": [
        "# ReAct document store\n",
        "from langchain.docstore.wikipedia import Wikipedia        # Wikipedia 문서 저장소를 사용\n",
        "from langchain.agents import Tool\n",
        "from langchain.agents.react.base import DocstoreExplorer  # 문서 저장소 탐색기 생성\n",
        "\n",
        "docstore=DocstoreExplorer(Wikipedia())\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Search\",\n",
        "        func=docstore.search,  # 키워드 기반 검색. \n",
        "        description=\"docstore에서 용어 검색\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Lookup\",\n",
        "        func=docstore.lookup, # 정확한 용어 방식 검색.\n",
        "        description=\"docstore에서 용어 검색\",\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Wmx_blJOMfhZ"
      },
      "outputs": [],
      "source": [
        "react = initialize_agent(tools = tools,\n",
        "                        llm = llm,\n",
        "                        agent = AgentType.REACT_DOCSTORE, # 에이전트 유형 ReAct document store\n",
        "                        handle_parsing_errors=True,       # 구문 오류 처리\n",
        "                        max_iterations=1,                 # 에이전트 최대 반복 횟수\n",
        "                        max_execution_time=5,             # 에이전트 작업 수행 최대 시간(초)\n",
        "                        verbose = True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djzJKErqMjS7",
        "outputId": "2faccfdb-0008-4421-d28e-4262d3c6902a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mCould not parse LLM Output: 샴 고양이에게 먹이를 주는 방법은 일반적인 고양이에게 먹이를 주는 방법과 크게 다르지 않습니다. 다음은 샴 고양이에게 적절한 먹이를 주기 위한 몇 가지 팁입니다:\n",
            "\n",
            "1. **균형 잡힌 식단 제공**: 샴 고양이에게는 고양이의 나이, 체중, 활동 수준에 맞는 균형 잡힌 식단을 제공해야 합니다. 고양이 사료는 주로 건식 사료와 습식 사료로 나뉘며, 둘 다 적절히 섞어서 주는 것이 좋습니다.\n",
            "\n",
            "2. **고품질 사료 선택**: 고양이의 건강을 위해 고품질의 사료를 선택하는 것이 중요합니다. 고양이 사료의 성분표를 확인하여 단백질 함량이 높은 제품을 선택하세요.\n",
            "\n",
            "3. **정기적인 식사 시간**: 고양이에게 정기적인 식사 시간을 정해주는 것이 좋습니다. 하루에 두세 번 정해진 시간에 먹이를 주면 고양이가 규칙적인 식습관을 갖게 됩니다.\n",
            "\n",
            "4. **적절한 양 조절**: 고양이의 체중과 건강 상태에 따라 먹이의 양을 조절해야 합니다. 과체중이 되지 않도록 주의하고, 필요에 따라 수의사와 상담하여 적절한 양을 결정하세요.\n",
            "\n",
            "5. **신선한 물 제공**: 항상 신선한 물을 제공하여 고양이가 충분한 수분을 섭취할 수 있도록 합니다.\n",
            "\n",
            "6. **간식은 적당히**: 간식은 고양이의 식단에 포함될 수 있지만, 너무 많이 주지 않도록 주의하세요. 간식은 전체 식단의 10%를 넘지 않도록 합니다.\n",
            "\n",
            "샴 고양이는 활동적이고 사회적인 성격을 가지고 있으므로, 건강한 식단과 함께 충분한 운동과 놀이 시간을 제공하는 것도 중요합니다.\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "response={'input': '샴 고양이에게 먹이주는 법은?', 'output': 'Agent stopped due to iteration limit or time limit.'}\n",
            "Agent stopped due to iteration limit or time limit.\n"
          ]
        }
      ],
      "source": [
        "def query_data(query):\n",
        "    try:\n",
        "        response = react.invoke(query)  # 질의 전달 에이전트 실행\n",
        "        print(f\"response={response}\")  \n",
        "        return response                 # 검색 결과 반환\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")            \n",
        "        raise \n",
        "\n",
        "query = \"샴 고양이에게 먹이주는 법은?\"\n",
        "response = query_data(query)\n",
        "print(response['output']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
