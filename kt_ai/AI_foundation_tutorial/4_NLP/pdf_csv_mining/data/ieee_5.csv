"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"CUDA accelerated iris template matching on Graphics Processing Units (GPUs)","N. A. Vandal; M. Savvides","Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15232, USA; Department of Electrical and Computer Engineering, Carnegie Mellon University","2010 Fourth IEEE International Conference on Biometrics: Theory, Applications and Systems (BTAS)","11 Nov 2010","2010","","","1","7","In this paper we develop a parallelized iris template matching implementation on inexpensive Graphics Processing Units (GPUs) with Nvidia's CUDA programming model to achieve matching rates of 44 million iris template comparisons per second without rotation invariance. With tolerance to head tilt, we achieve 4.2 million matches per second and compare our implementation to state of the art prior work performed on GPU and FPGA, emphasizing our improvements. Additionally a comparison to highly optimized CPU implementations of iris template matching is performed, showing a 14X speedup using our approach. In contrast to other published work, we develop an implementation for parallel iris template matching that incorporates iris code shifting for rotation invariance and provide timing data showing our proposed architecture is efficiently implemented, capitalizing on shared and texture memory to speedup the bit shifting process beyond current prior art.","","978-1-4244-7582-7","10.1109/BTAS.2010.5634505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5634505","","Iris recognition;Instruction sets;Probes;Graphics processing unit;Field programmable gate arrays;Hamming distance;Hardware","computer graphic equipment;coprocessors;field programmable gate arrays;image matching;iris recognition","iris template matching;graphics processing units;Nvidia CUDA programming model;field programmable gate array;bit shifting process","","12","1","20","","11 Nov 2010","","","IEEE","IEEE Conferences"
"GPGPU-Based ATPG System: Myth or Reality?","L. Lai; K. -H. Tsai; H. Li","Department of Electrical Engineering, Shantou University, Shantou, China; Silicon Test Division, Mentor Graphics Corporation, Wilsonville, OR, USA; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","23 Dec 2019","2020","39","1","239","247","General-purpose computing on graphics processing units (GPGPUs) is a programming model that uses graphics cards to perform computations traditionally done by CPU. It began to become practical with the advent of programmable shaders and floating-point support on GPU in around 2001. The spread of GPGPU has been accelerated with introduction of CUDA from NVIDIA in 2006 and later OpenCL in 2009. Nowadays GPGPU is widely deployed in various applications, such as data mining, artificial intelligence, and many scientific computations. GPGPU seemingly promises immense parallelism with massive concurrent cores, and thus much shorter run times. This is true for algorithms that bear intrinsic data and task parallelism, such as image and video processing. For an ATPG system where some algorithms are sequential in nature, the speedup is not easy to achieve in the real world. Flaws in setting up speedup evaluation can lead to false promises. Will GPGPU-based ATPG system become a reality? Or it is just a myth. In this paper, we try to provide an answer by surveying state-of-the-art works and by analyzing practical aspects of today's industrial designs.","1937-4151","","10.1109/TCAD.2018.2884992","Shantou University(grant numbers:140-760163); Yangfang Career Award of Guangdong Province, China(grant numbers:140-14600602); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8558526","ATPG;fault simulation;general-purpose computing on graphics processing units (GPGPUs)","Graphics processing units;Memory management;Instruction sets;Integrated circuit modeling;Circuit faults;Test pattern generators;Kernel","automatic test pattern generation;general purpose computers;graphics processing units;parallel architectures","OpenCL;CUDA;task parallelism;floating-point support;programmable shaders;programming model;general-purpose computing;GPGPU-based ATPG system","","1","","42","IEEE","4 Dec 2018","","","IEEE","IEEE Journals"
"Flacc: Towards OpenACC support for Fortran in the LLVM Ecosystem","V. Clement; J. S. Vetter","Oak Ridge National Laboratory,Programming Systems Group; Oak Ridge National Laboratory,Advanced Computing Systems Research Section","2021 IEEE/ACM 7th Workshop on the LLVM Compiler Infrastructure in HPC (LLVM-HPC)","20 Dec 2021","2021","","","12","19","OpenACC is a directive-based programming model for heterogeneous accelerators initially launched in 2010 to provide a portable solution at a level of abstraction above OpenCL, CUDA, and other lower-level programming models. Various implementations of OpenACC for C, C++, and Fortran exist; however, only one open-source, production implementation of OpenACC for Fortran does exist. Moreover, most contemporary compiler tool chains for heterogeneous computing are based on LLVM. This lack of support poses a serious risk for high-performance computing application developers targeting GPUs and other accelerators, and it limits the ability of the community to experiment with, extend, and contribute to the OpenACC specification and open-source implementation itself. To address this gap, we have designed and begun implementing Flacc: an effort funded by the US Exascale Computing Project to develop production OpenACC compiler support for Fortran based on Flang within the LLVM ecosystem. In this paper, we describe the Flacc goals, initial design and prototype, and challenges that we have encountered so far in our prototyping efforts. Flacc is implemented as a MLIR dialect in the Flang Fortran front end in LLVM. The Flacc front end currently supports OpenACC version 3.1, and the Flacc run time is currently under development and relies on contributions from the Clacc project. Current contributions to Flacc are available in the main ${\color{Green}{\mathbf{LLVM}}\;{\mathbf{repository}}}$.<sup>1</sup>","","978-1-6654-1134-9","10.1109/LLVMHPC54804.2021.00007","Office of Science; UT-Battelle; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9651310","OpenACC;OpenMP;LLVM;MLIR;multicore;GPU;accelerators;compiler","Codes;Exascale computing;Ecosystems;Semantics;Prototypes;Graphics processing units;Production","","","","","","26","","20 Dec 2021","","","IEEE","IEEE Conferences"
"Performance Portability Evaluation of OpenCL Benchmarks across Intel and NVIDIA Platforms","C. Bertoni; J. Kwack; T. Applencourt; Y. Ghadar; B. Homerding; C. Knight; B. Videau; H. Zheng; V. Morozov; S. Parker","Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439; Argonne National Laboratory,Argonne Leadership Computing Facility,Lemont,IL,USA,60439","2020 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","28 Jul 2020","2020","","","330","339","We evaluate the capabilities of vendor-provided OpenCL implementations for performance portability across multiple computing platforms. The Rodinia benchmark suite is used for this evaluation. We apply the metric defined by Pennycook et al., and we use roofline efficiency from the Roofline performance model as the “performance efficiency” in the metric's definition. We found that the delivered performance portability is similar for several benchmarks, even if the roofline-based performance efficiencies across platforms are very different among the benchmarks. To help distinguish between these instances, we extend the metric by adding the standard deviation of the performance efficiencies for each benchmark. We argue that the standard deviation gives additional insight into performance portability assessment since it adds the performance variability across platforms. Additionally, we discuss the challenges to measure performance portability associated with algorithms and system software. In terms of algorithms, we need to carefully construct the benchmarks and appropriately use the concurrency available on a platform. In terms of system software, we depend on the vendor performance tools to support the desired programming model and runtime to be able to measure the metrics of interest.","","978-1-7281-7445-7","10.1109/IPDPSW50202.2020.00067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150432","high performance computing;performance efficiency;performance portability;roofline performance analysis;OpenCL;GPU","Benchmark testing;Computer architecture;Measurement;Computational modeling;Kernel;Programming;Bandwidth","application program interfaces;concurrency control;graphics processing units;parallel processing;software metrics;software performance evaluation","performance portability evaluation;OpenCL benchmarks;Rodinia benchmark suite;roofline efficiency;roofline performance model;performance portability assessment;performance variability;vendor performance tools;NVIDIA platform;Intel platform;OpenCL implementations;concurrency","","3","","26","","28 Jul 2020","","","IEEE","IEEE Conferences"
"Reactive Molecular Dynamics on Massively Parallel Heterogeneous Architectures","S. B. Kylasa; H. M. Aktulga; A. Y. Grama","Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN; Michigan State University, 428 S. Shaw Lane, Room 3115, East Lansing, MI; Department of Computer Science, Purdue University, West Lafayette, IN","IEEE Transactions on Parallel and Distributed Systems","9 Dec 2016","2017","28","1","202","214","We present a parallel implementation of the ReaxFF force field on massively parallel heterogeneous architectures, called PuReMD-Hybrid. PuReMD, on which this work is based, along with its integration into LAMMPS, is currently used by a large number of research groups worldwide. Accelerating this important community codebase that implements a complex reactive force field poses a number of algorithmic, design, and optimization challenges, as we discuss in detail. In particular, different computational kernels are best suited to different computing substrates-CPUs or GPUs. Scheduling these computations requires complex resource management, as well as minimizing data movement across CPUs and GPUs. Integrating powerful nodes, each with multiple CPUs and GPUs, into clusters and utilizing the immense compute power of these clusters requires significant optimizations for minimizing communication and, potentially, redundant computations. From a programming model perspective, PuReMD-Hybrid relies on MPI across nodes, pthreads across cores, and CUDA on the GPUs to address these challenges. Using a variety of innovative algorithms and optimizations, we demonstrate that our code can achieve over 565-fold speedup compared to a single core implementation on a cluster of 36 state-of-the-art GPUs for complex systems. In terms of application performance, our code enables simulations of over 1.8M atoms in under 0.68 seconds per simulation time step.","1558-2183","","10.1109/TPDS.2016.2548462","National Science Foundation(grant numbers:CCF 1533795); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7444209","Reactive molecular dynamics;parallel GPU implementations;material simulations","Graphics processing units;Force;Kernel;Biological system modeling;Computational modeling;Clustering algorithms;Numerical models","graphics processing units;microprocessor chips;molecular dynamics method;parallel architectures","CUDA;pthreads across cores;MPI across nodes;data movement;complex resource management;GPUs;CPUs;computing substrates;computational kernels;complex reactive force field;LAMMPS;PuReMD-hybrid;ReaxFF force field;massively parallel heterogeneous architectures;reactive molecular dynamics","","10","","45","IEEE","30 Mar 2016","","","IEEE","IEEE Journals"
"Understanding Error Propagation in GPGPU Applications","G. Li; K. Pattabiraman; C. -Y. Cher; P. Bose","Univ. of British Columbia, Vancouver, BC, Canada; Univ. of British Columbia, Vancouver, BC, Canada; T.J. Watson Res. Center, IBM, Yorktown Heights, NY, USA; T.J. Watson Res. Center, IBM, Yorktown Heights, NY, USA","SC '16: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","16 Mar 2017","2016","","","240","251","GPUs have emerged as general-purpose accelerators in high-performance computing (HPC) and scientific applications. However, the reliability characteristics of GPU applications have not been investigated in depth. While error propagation has been extensively investigated for non-GPU applications, GPU applications have a very different programming model which can have a significant effect on error propagation in them. We perform an empirical study to understand and characterize error propagation in GPU applications. We build a compilerbased fault-injection tool for GPU applications to track error propagation, and define metrics to characterize propagation in GPU applications. We find GPU applications exhibit significant error propagation for some kinds of errors, but not others, and the behaviour is highly application specific. We observe the GPUCPU interaction boundary naturally limits error propagation in these applications compared to traditional non-GPU applications. We also formulate various guidelines for the design of faulttolerance mechanisms in GPU applications based on our results.","2167-4337","978-1-4673-8815-3","10.1109/SC.2016.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7877099","Fault Injection;Error Resilience;GPGPU;CUDA;Error Propagation","Graphics processing units;Kernel;Circuit faults;Hardware;Programming;Computational modeling;Central Processing Unit","graphics processing units;parallel processing;program compilers;software reliability","error propagation;GPGPU;general-purpose accelerators;high-performance computing;HPC;reliability characteristics;compiler-based fault-injection tool","","43","","55","","16 Mar 2017","","","IEEE","IEEE Conferences"
"RAJA: Portable Performance for Large-Scale Scientific Applications","D. A. Beckingsale; J. Burmark; R. Hornung; H. Jones; W. Killian; A. J. Kunen; O. Pearce; P. Robinson; B. S. Ryujin; T. R. Scogland","Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA; Lawrence Liveremore National Laboratory, USA","2019 IEEE/ACM International Workshop on Performance, Portability and Productivity in HPC (P3HPC)","2 Jan 2020","2019","","","71","81","Modern high-performance computing systems are diverse, with hardware designs ranging from homogeneous multi- core CPUs to GPU or FPGA accelerated systems. Achieving desir- able application performance often requires choosing a program- ming model best suited to a particular platform. For large codes used daily in production that are under continual development, architecture-specific ports are untenable. Maintainability re- quires single-source application code that is performance portable across a range of architectures and programming models. In this paper we describe RAJA, a portability layer that enables C++ applications to leverage various programming models, and thus architectures, with a single-source codebase. We describe preliminary results using RAJA in three large production codes at Lawrence Livermore National Laboratory, observing 17×, 13× and 12× speedup on GPU-only over CPU- only nodes with single-source application code in each case.","","978-1-7281-6003-0","10.1109/P3HPC49587.2019.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945721","","C++ languages;Graphics processing units;Programming;Production;Computer architecture;Kernel;Libraries","application program interfaces;field programmable gate arrays;graphics processing units;microprocessor chips;multiprocessing systems;parallel processing;software portability","C++ applications;single-source codebase;RAJA;production codes;high-performance computing systems;hardware designs;programming model;architecture-specific ports;homogeneous multicore CPU;Lawrence Livermore National Laboratory","","21","","23","","2 Jan 2020","","","IEEE","IEEE Conferences"
"Directive-based Programming for GPUs: A Comparative Study","R. Reyes; I. López; J. J. Fumero; F. de Sande","Dept. de EIO y Comput., Univ. de La Laguna, La Laguna, Spain; Dept. de EIO y Comput., Univ. de La Laguna, La Laguna, Spain; Dept. de EIO y Comput., Univ. de La Laguna, La Laguna, Spain; Dept. de EIO y Comput., Univ. de La Laguna, La Laguna, Spain","2012 IEEE 14th International Conference on High Performance Computing and Communication & 2012 IEEE 9th International Conference on Embedded Software and Systems","18 Oct 2012","2012","","","410","417","GPUs and other accelerators are available on many different devices, while GPGPU has been massively adopted by the HPC research community. Although a plethora of libraries and applications providing GPU support are available, the need of implementing new algorithms from scratch, or adapting sequential programs to accelerators, will always exist. Writing CUDA or OpenCL codes, although an easier task than using their predecessors, is not trivial. Obtaining performance is even harder, as it requires deep understanding of the underlying architecture. Some efforts have been directed toward the automatic code generation for GPU devices, with different results. In particular, several directive-oriented programming models, taking advantage of the OpenMP success, have been created. Although future OpenMP releases will integrate accelerators into the standard, tools are needed in the meantime. In this work, we present a comparison between three directive-based programming models: hiCUDA, PGI Accelerator and OpenACC, using for the last our novel accULL implementation. With this comparison, we aim to showcase the evolution of the directive-based programming models and how users can guide tools toward better performance results.","","978-1-4673-2164-8","10.1109/HPCC.2012.62","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6332201","OpenACC;PGI;Accelerators;GPGPU;CUDA;OpenCL;OpenMP;compiler;productivity","Graphics processing unit;Kernel;Programming;Standards;Runtime;Performance evaluation","graphics processing units;multiprocessing systems;parallel architectures;program compilers","directive-based programming model;GPGPU;HPC;scratch;automatic code generation;OpenMP;hiCUDA;PGI accelerator;OpenACC;accULL","","13","1","14","","18 Oct 2012","","","IEEE","IEEE Conferences"
"Liszt: A domain specific language for building portable mesh-based PDE solvers","Z. DeVito; N. Joubert; F. Palacios; S. Oakley; M. Medina; M. Barrientos; E. Elsen; F. Ham; A. Aiken; K. Duraisamy; E. Darve; J. Alonso; P. Hanrahan","Department of Computer Science, Stanford University; Department of Computer Science, Stanford University; Department of Aeronautics and Astronautics, Stanford University; Institute for Computational and Mathematical Engineering, Stanford University; Institute for Computational and Mathematical Engineering, Stanford University; Department of Computer Science, Stanford University; Department of Mechanical Engineering, Stanford University; Department of Mechanical Engineering, Stanford University; Department of Computer Science, Stanford University; Department of Aeronautics and Astronautics, Stanford University; Department of Mechanical Engineering, Stanford University; Department of Aeronautics and Astronautics, Stanford University; Department of Computer Science, Stanford University","SC '11: Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis","29 Dec 2011","2011","","","1","12","Heterogeneous computers with processors and accelerators are becoming widespread in scientific computing. However, it is difficult to program hybrid architectures and there is no commonly accepted programming model. Ideally, applications should be written in a way that is portable to many platforms, but providing this portability for general programs is a hard problem. By restricting the class of programs considered, we can make this portability feasible. We present Liszt, a domain- specific language for constructing mesh-based PDE solvers. We introduce language statements for interacting with an unstructured mesh, and storing data at its elements. Pro- gram analysis of these statements enables our compiler to expose the parallelism, locality, and synchronization of Liszt programs. Using this analysis, we generate applications for multiple platforms: a cluster, an SMP, and a GPU. This approach allows Liszt applications to perform within 12% of hand-written C++, scale to large clusters, and experience order-of-magnitude speedups on GPUs.","2167-4337","978-1-4503-0771-0","10.1145/2063384.2063396","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6114401","compiler analysis and program transformations;programming and runtime environments for high performance and high throughput computing","Jacobian matrices;Face;Hardware;Computer architecture;Synchronization;Graphics processing unit;Heating","graphics processing units;mathematics computing;mesh generation;partial differential equations;program compilers;program diagnostics;specification languages","domain specific language;portable mesh-based PDE solver;heterogeneous computers;scientific computing;language statements;program analysis;compiler;Liszt programs;cluster;SMP;GPU;C++;partial differential equations","","34","","36","","29 Dec 2011","","","IEEE","IEEE Conferences"
"TC-Release++: An Efficient Timestamp-Based Coherence Protocol for Many-Core Architectures","Y. Yao; W. Chen; T. Mitra; Y. Xiang","School of Computer Science and Technology, Zhejiang University, Hangzhou, P.R. China; School of Computer Science and Technology, Zhejiang University, Hangzhou, P.R. China; School of Computing, National University of Singapore, Singapore; Swinburne Research, Swinburne University of Technology, Hawthorn, Victoria, Australia","IEEE Transactions on Parallel and Distributed Systems","9 Oct 2017","2017","28","11","3313","3327","As we enter the era of many-core, providing the shared memory abstraction through cache coherence has become progressively difficult. The standard directory-based coherence does not scale well with increasing core count. Timestamp-based hardware coherence protocols introduced recently offer an attractive alternative solution. This paper proposes a timestamp-based coherence protocol, called TC-Release<sub>++</sub>, that efficiently supports cache coherence in large-scale systems. Our approach is inspired by TC-Weak, a recently proposed timestamp-based coherence protocol targeting GPU architectures. We first design TC-Release in an attempt to straightforwardly port TC-Weak to general-purpose many-cores. But re-purposing TC-Weak for general-purpose many-core architectures is challenging due to significant differences both in architecture and the programming model. Indeed the performance of TC-Release turns out to be worse than conventional directory protocols. We overcome the limitations and overheads of TC-Release by exploiting simple hardware support to eliminate frequent memory stalls, and an optimized lifetime prediction mechanism to improve cache performance. The resulting optimized coherence protocol TC-Release<sub>++</sub> is highly scalable (storage scales logarithmically with core count) and shows better performance (3.0 percent) and comparable network traffic (within 1.3 percent) relative to the baseline MESI directory protocol. We use Murphi to formally verify that TC-Release<sub>++</sub> is error-free and imposes small verification cost.","1558-2183","","10.1109/TPDS.2017.2719679","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7959101","Cache coherence;many-core architecture;timestamp-based system;memory consistency model","Coherence;Protocols;Graphics processing units;Hardware;Memory management;Programming;Electronic mail","cache storage;graphics processing units;multiprocessing systems;protocols;shared memory systems","general-purpose many-cores;re-purposing TC;general-purpose many-core architectures;conventional directory protocols;resulting optimized coherence protocol TC;core count;baseline MESI directory protocol;shared memory abstraction;cache coherence;timestamp-based hardware coherence protocols;GPU architectures;design TC","","2","","43","IEEE","26 Jun 2017","","","IEEE","IEEE Journals"
"Optimal balance between energy and performance in hybrid computing applications","D. LaKomski; Z. Zong; T. Jin; R. Ge","Computer Science Department, Texas State University, USA; Computer Science Department, Texas State University, USA; Ingram School of Engineering, Texas State University, USA; School of Computing, Clemson University, USA","2015 Sixth International Green and Sustainable Computing Conference (IGSC)","28 Jan 2016","2015","","","1","8","The latest top 10 supercomputers are dominated by heterogeneous systems with CPUs and accelerators (GPU or Xeon Phi) tightly coupled together. As the heterogeneity of future high performance computing systems keeps increasing, it becomes paramount to judiciously use CPUs and accelerators to improve performance and/or reduce energy consumption. The widely used programming model today is to offload computation intensive workload to accelerators. Theoretically, the hybrid computing model (i.e. running a subset of calculations concurrently on both CPUs and accelerators) can potentially offer advantages of improved energy efficiency and performance. However, this is not yet a common practice due to the uncertainty of energy/performance benefits as well as the increased programming complexity. In this paper, we conduct a comprehensive study on achieving the balance between energy and performance of hybrid computing applications. We show that performance and energy optimization can be conflicting goals, the sweet spot between performance and energy consumption varies with application characteristics and is highly dependent on specific implementations, that the choice of compiler can not only influence runtime but also energy use, and that the choice of cross platform strategies (e.g. OpenCL) can result in degraded performance and increased energy.","","978-1-5090-0172-9","10.1109/IGCC.2015.7393697","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7393697","energy efficient computing;green programming;hybrid computing;heterogeneous systems;performance optimization","Graphics processing units;Runtime;Programming;Fractals;Energy consumption;Computational modeling;Performance evaluation","energy consumption;graphics processing units;optimisation;parallel machines","optimal balance;hybrid computing application;supercomputers;CPU;accelerator;GPU;Xeon Phi;high performance computing system;energy consumption;energy efficiency;energy optimization;OpenCL","","4","","29","","28 Jan 2016","","","IEEE","IEEE Conferences"
"Towards a robust, real-time face processing system using CUDA-enabled GPUs","B. Sharma; R. Thota; N. Vydyanathan; A. Kale","Siemens Corporate Technology, Bangalore, India; Siemens Corporate Technology, Bangalore, India; Siemens Corporate Technology, Bangalore, India; Siemens Corporate Technology, Bangalore, India","2009 International Conference on High Performance Computing (HiPC)","18 Mar 2010","2009","","","368","377","Processing of human faces finds application in various domains like law enforcement and surveillance, entertainment (interactive video games), information security, smart cards etc. Several of these applications are interactive and require reliable and fast face processing. A generic face processing system may comprise of face detection, recognition, tracking and rendering. In this paper, we develop a GPU accelerated real-time and robust face processing system that does face detection and tracking. Face detection is done by adapting the Viola and Jones algorithm that is based on the Adaboost learning system. For robust tracking of faces across real-life illumination conditions, we leverage the algorithm proposed by Thota and others, that combines the strengths of Adaboost and an image based parametric illumination model. We design and develop optimized parallel implementations of these algorithms on graphics processors using the Compute Unified Device Architecture (CUDA), a C-based programming model from NVIDIA. We evaluate our face processing system using both static image databases as well as using live frames captured from a firewire camera under realistic conditions. Our experimental results indicate that our parallel face detector and tracker achieve much greater detection speeds as compared to existing work, while maintaining accuracy. We also demonstrate that our tracking system is robust to extreme illumination conditions.","1094-7256","978-1-4244-4921-7","10.1109/HIPC.2009.5433189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5433189","Parallel computing;face detection;face tracking;graphics processors;real-time algorithms","Robustness;Real time systems;Face detection;Lighting;Firewire;Humans;Law enforcement;Surveillance;Games;Information security","C language;computer graphic equipment;computer graphics;coprocessors;face recognition","face processing system;CUDA-enabled GPU;face detection;face tracking;Viola-Jones algorithm;Adaboost learning system;image based parametric illumination model;compute unified device architecture;C-based programming","","30","2","15","","18 Mar 2010","","","IEEE","IEEE Conferences"
"Static WCET Analysis of GPUs with Predictable Warp Scheduling","Y. Huangfu; W. Zhang","Virginia Commonwealth Univ., Richmond, VA, USA; Virginia Commonwealth Univ., Richmond, VA, USA","2017 IEEE 20th International Symposium on Real-Time Distributed Computing (ISORC)","3 Jul 2017","2017","","","101","108","The capability of GPUs to accelerate general-purpose applications that can be parallelized into massive number of threads makes it promising to apply GPUs to real-time applications as well, where high throughput and intensive computation are also needed. However, due to the different architecture and programming model of GPUs, the worst-case execution time (WCET) analysis methods and techniques designed for CPUs cannot be used directly to estimate the WCET of GPUs. In this work, based on the analysis of the architecture and dynamic behavior of GPUs, we propose a WCET timing model and analyzer based on a predictable GPU warp scheduling policy to enable the WCET estimation on GPUs.","2375-5261","978-1-5386-1574-4","10.1109/ISORC.2017.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7964876","","Graphics processing units;Instruction sets;Kernel;Analytical models;Computer architecture;Mathematical model;Dynamic scheduling","general purpose computers;graphics processing units;microprocessor chips;parallel processing;program diagnostics;scheduling","GPU;predictable warp scheduling;general purpose applications;static worst-case execution time analysis;static WCET analysis;CPU","","4","","23","","3 Jul 2017","","","IEEE","IEEE Conferences"
"Performance Portability of an SpMV Kernel Across Scientific Computing and Data Science Applications","S. L. Olivier; N. D. Ellingwood; J. Berry; D. M. Dunlavy","Sandia National Laboratories,Albuquerque,NM; Sandia National Laboratories,Albuquerque,NM; Sandia National Laboratories,Albuquerque,NM; Sandia National Laboratories,Albuquerque,NM","2021 IEEE High Performance Extreme Computing Conference (HPEC)","1 Dec 2021","2021","","","1","8","Both the data science and scientific computing communities are embracing GPU acceleration for their most demanding workloads. For scientific computing applications, the massive volume of code and diversity of hardware platforms at supercomputing centers has motivated a strong effort toward performance portability. This property of a program, denoting its ability to perform well on multiple architectures and varied datasets, is heavily dependent on the choice of parallel programming model and which features of the programming model are used. In this paper, we evaluate performance portability in the context of a data science workload in contrast to a scientific computing workload, evaluating the same sparse matrix kernel on both. Among our implementations of the kernel in different performance-portable programming models, we find that many struggle to consistently achieve performance improvements using the GPU compared to simple one-line OpenMP parallelization on high-end multicore CPUs. We show one that does, and its performance approaches and sometimes even matches that of vendor-provided GPU math libraries.","2643-1971","978-1-6654-2369-4","10.1109/HPEC49654.2021.9622869","National Nuclear Security Administration; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622869","performance portability;SpMV;sparse matrix operations;graph computations","Runtime;Codes;Scientific computing;Multicore processing;Computational modeling;Graphics processing units;Computer architecture","","","","","","27","","1 Dec 2021","","","IEEE","IEEE Conferences"
"Single Kernel Soft Synchronization Technique for Task Arrays on CUDA-enabled GPUs, with Applications","S. Funasaka; K. Nakano; Y. Ito","Dept. of Inf. Eng., Hiroshima Univ., Higashi-Hiroshima, Japan; Dept. of Inf. Eng., Hiroshima Univ., Higashi-Hiroshima, Japan; Dept. of Inf. Eng., Hiroshima Univ., Higashi-Hiroshima, Japan","2017 Fifth International Symposium on Computing and Networking (CANDAR)","26 Apr 2018","2017","","","11","20","A task array is a 2-dimensional array of tasks with dependency relations. Each task uses the resulting values of some tasks in the left columns, and so it can be started only after these left tasks are completed. Conventional CUDA implementations repeatedly perform a separated CUDA kernel call for each column from left to right to synchronize the computation for tasks. However, this conventional CUDA implementation has several drawbacks: a CUDA kernel call has a certain overhead, and the running time of a CUDA kernel is determined by a CUDA block that terminates lastly. Also, every task must write and preserve the resulting values in the global memory with low memory access performance for the following tasks. The main contribution of this paper is to introduce task arrays and to present Single Kernel Soft Synchronization (SKSS) technique that significantly reduces such overheads for task arrays. The SKSS performs only one CUDA kernel call and CUDA blocks assigned to each row of a task array using a global counter. To clarify the potentiality of our SKSS technique, we have implemented the dynamic programming for the 0-1 knapsack problem, the summed area table computation, and the error diffusion of a gray-scale image using our SKSS technique and compared with previously published best GPU implementations. Quite surprisingly, the experimental results using NVIDIA Titan X show that, our SKSS implementations are 1.29-2.11 times faster for the 0-1 knapsack problem, 1.08-1.56 times faster for the summed area table computation, and 1.61-2.11 times faster for the error diffusion.","2379-1896","978-1-5386-2087-8","10.1109/CANDAR.2017.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8345405","dynamic programming;knapsack problem;summed area table;error diffusion","Graphics processing units;Task analysis;Kernel;Parallel algorithms;Synchronization;Computer architecture;Dynamic programming","dynamic programming;graphics processing units;operating system kernels;parallel algorithms;parallel architectures;parallel programming;synchronisation","task array;CUDA block;SKSS technique;CUDA-enabled GPUs;Single Kernel Soft Synchronization;CUDA kernel call;dynamic programming;knapsack problem;summed area table computation;error diffusion;parallel computing architecture;Compute Unified Device Architecture;CUDA programming model;parallel algorithms","","12","","16","","26 Apr 2018","","","IEEE","IEEE Conferences"
"Parallelization of Virtual Screening in Drug Discovery on Massively Parallel Architectures","G. D. Guerrero; H. E. Perez-S´nchez; J. M. Cecilia; J. M. Garcia","Dipt. de Ing. y Tecnol. de Comput., Univ. de Murcia, Murcia, Spain; NA; Dipt. de Ing. y Tecnol. de Comput., Univ. de Murcia, Murcia, Spain; Dipt. de Ing. y Tecnol. de Comput., Univ. de Murcia, Murcia, Spain","2012 20th Euromicro International Conference on Parallel, Distributed and Network-based Processing","15 Mar 2012","2012","","","588","595","The current trend in medical research for the discovery of new drugs is the use of Virtual Screening (VS) methods. In these methods, the calculation of the non-bonded interactions, such as electrostatics or van der Waals forces, plays an important role, representing up to 80% of the total execution time. These kernels are computational intensive and massively parallel in nature, and thus they are well suited to be accelerated on parallel architectures. In this work, we discuss the effective parallelization of the non-bonded electrostatic interactions kernel for VS on three different parallel architectures: a shared memory system, a distributed memory system, and a Graphics Processing Units (GPUs). For an efficient handling of the computational intensive and massively parallelism of this kernel, we enable different data policies on those architectures to take advantage of all computational resources offered by them. Four implementations are provided based on MPI, OpenMP, Hybrid MPI Open MP and CUDA programming models. The sequential implementation is defeated by a wide margin by all parallel implementations, obtaining up to 72x speed-up factor on the shared memory system through OpenMP, up to 60x and229x speed-ups factors on the distributed memory system for the MPI implementation and the Hybrid MPI-Open MP implementation respectively, and finally, up to 213x speedup factor for the CUDA implementation on the GPU architecture to offer the best alternative in terms of performance/cost ratio.","2377-5750","978-1-4673-0226-5","10.1109/PDP.2012.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169645","Drug Discovery;Non-bonded interactions;CUDA;OpenMP;MPI;Hybrid OpenMP-MPI;High-Performance Computing","Graphics processing unit;Kernel;Instruction sets;Message systems;Parallel processing;Programming;Computer architecture","application program interfaces;distributed shared memory systems;graphics processing units;medical computing;message passing;parallel architectures","virtual screening parallelization;drug discovery;massively parallel architecture;medical research;virtual screening method;electrostatics;van der Waals force;shared memory system;distributed memory system;graphics processing units;data policy;computational resource;CUDA programming model;message passing interface;compute unified device architecture;sequential implementation;parallel implementation;performance-cost ratio;speedup factor;hybrid MPI openMP","","8","","29","","15 Mar 2012","","","IEEE","IEEE Conferences"
"Scalable Programming Models for Massively Multicore Processors","M. D. McCool","Rapid Mind Inc., Waterloo","Proceedings of the IEEE","15 Apr 2008","2008","96","5","816","831","Including multiple cores on a single chip has become the dominant mechanism for scaling processor performance. Exponential growth in the number of cores on a single processor is expected to lead in a short time to mainstream computers with hundreds of cores. Scalable implementations of parallel algorithms will be necessary in order to achieve improved single-application performance on such processors. In addition, memory access will continue to be an important limiting factor on achieving performance, and heterogeneous systems may make use of cores with varying capabilities and performance characteristics. An appropriate programming model can address scalability and can expose data locality while making it possible to migrate application code between processors with different parallel architectures and variable numbers and kinds of cores. We survey and evaluate a range of multicore processor architectures and programming models with a focus on GPUs and the Cell BE processor. These processors have a large number of cores and are available to consumers today, but the scalable programming models developed for them are also applicable to current and future multicore CPUs.","1558-2256","","10.1109/JPROC.2008.917731","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4490125","Computer architecture;multicore processors;parallel programming and computation;programming and processing models","Multicore processing;Parallel processing;Parallel programming;Concurrent computing;Hardware;Computer architecture;Programming profession;Pipeline processing;Parallel algorithms;Scalability","microprocessor chips;parallel algorithms;parallel architectures","scalable programming models;multicore processors;parallel algorithms;heterogeneous systems;parallel architectures;GPU;cell BE processor;graphics processing units","","32","25","64","","15 Apr 2008","","","IEEE","IEEE Journals"
"Enable OpenCL Compiler with Open64 Infrastructures","Y. Lin; S. Wang; W. Shih; B. K. Hsieh; J. Lee","Dept. of Comput. Sci., Nat. Tsing-Hua Univ., Hsinchu, Taiwan; Dept. of Comput. Sci., Nat. Tsing-Hua Univ., Hsinchu, Taiwan; Dept. of Comput. Sci., Nat. Tsing-Hua Univ., Hsinchu, Taiwan; Cloud Comput. Res. Center for Mobile Applic., Ind. Technol. Res. Inst., Hsinchu, Taiwan; Dept. of Comput. Sci., Nat. Tsing-Hua Univ., Hsinchu, Taiwan","2011 IEEE International Conference on High Performance Computing and Communications","31 Oct 2011","2011","","","863","868","As microprocessors evolve into heterogeneous architectures with multi-cores of MPUs and GPUs, programming model supports become important for programming such architectures. To address this issue, OpenCL is proposed. Currently, most of OpenCL implementations take LLVM as their infrastructures. This presents an opportunity to demonstrate whether OpenCL can be effectively implemented on other compiler infrastructures. For example, Open64, which is another open source compiler and known to generate efficient codes for microprocessors, can contribute further to performance improvements and enhancing the adoption of heterogeneous computing based on OpenCL. In this paper, we describe the flow to enable an OpenCL compiler based on Open64 infrastructures for ATI GPUs. Our work includes the extension of the front-end parser for OpenCL, the generation of high-level intermediate representations with OpenCL linguistics, performing high-level optimization, and finally applying OpenCL specific optimization for code generations. Preliminary experimental results show that our compiler based on Open64 is able to generate efficient codes for OpenCL programs.","","978-1-4577-1564-8","10.1109/HPCC.2011.123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6063089","","Vectors;Registers;Optimization;Programming;Graphics processing unit;Hardware;Computer architecture","computer architecture;microprocessor chips;optimising compilers","OpenCL compiler;Open64 infrastructure;microprocessor;heterogeneous architecture;MPU;LLVM;open source compiler;ATI GPU;front-end parser;OpenCL linguistics;code generation","","5","","23","","31 Oct 2011","","","IEEE","IEEE Conferences"
"Performance Portability across Diverse Computer Architectures","T. Deakin; S. McIntosh-Smith; J. Price; A. Poenaru; P. Atkinson; C. Popa; J. Salmon","University of Bristol, UK; University of Bristol, UK; University of Bristol, UK; University of Bristol, UK; University of Bristol, UK; University of Bristol, UK; University of Bristol, UK","2019 IEEE/ACM International Workshop on Performance, Portability and Productivity in HPC (P3HPC)","2 Jan 2020","2019","","","1","13","Previous studies into performance portability have typically analysed a single application (and its various imple- mentations) in isolation. In this study we explore the wider landscape of performance portability by considering a number of applications from across the space of dwarfs, written in multiple parallel programming models, and across a diverse set of architectures. We apply rigorous performance portability metrics, as defined by Pennycook et al [1]. We believe this is the broadest and most rigorous performance portability study to date, representing a far reaching exploration of the state of performance portability that is achievable today. We will present a summary of the performance portability of each application and programming model across our diverge range of twelve computer architectures, including six different server CPUs from five different vendors, five different GPUs from two different vendors, and one vector architecture. We will conclude with an analysis of the performance portability of key programming models in general, across different application spaces as well across differing architectures, allowing us to comment on more general performance portability principles.","","978-1-7281-6003-0","10.1109/P3HPC49587.2019.00006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945642","performance portability;productivity;mini-app;programming models","Productivity;Analytical models;Computational modeling;Computer architecture;Programming;Hardware;Standards","coprocessors;multiprocessing systems;parallel programming","performance portability principles;performance portability study;performance portability metrics;programming models;GPU","","11","","19","","2 Jan 2020","","","IEEE","IEEE Conferences"
"A CUDA-based parallel implementation of K-nearest neighbor algorithm","S. Liang; Y. Liu; C. Wang; L. Jian","Graduate University of Chinese Academy of Sciences, Beijing, China; Graduate University of Chinese Academy of Sciences, Beijing, China; Agilent Technologies Co. Ltd., Beijing, China; Graduate University of Chinese Academy of Sciences, Beijing, China","2009 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery","26 Jan 2010","2009","","","291","296","Recent developments in Graphics Processing Units (GPUs) have enabled inexpensive high performance computing for general-purpose applications. Due to GPU's tremendous computing capability, it has emerged as the co-processor of the CPU to achieve a high overall throughput. CUDA programming model provides the programmers adequate C language like APIs to better exploit the parallel power of the GPU. K-nearest neighbor (KNN) is a widely used classification technique and has significant applications in various domains, especially in text classification. The computational-intensive nature of KNN requires a high performance implementation. In this paper, we present a CUDA-based parallel implementation of KNN, CUKNN, using CUDA multi-thread model, where the data elements are processed in a data-parallel fashion. Various CUDA optimization techniques are applied to maximize the utilization of the GPU. CUKNN outperforms the serial KNN on an HP xw8600 workstation significantly, achieving up to 46.71X speedup including I/O time. It also shows good scalability when varying the dimension of the reference dataset, the number of records in the reference dataset, and the number of records in the query dataset.","","978-1-4244-5218-7","10.1109/CYBERC.2009.5399145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5399145","KNN, classification, parallel computing, CUDA","High performance computing;Graphics;Coprocessors;Central Processing Unit;Throughput;Parallel programming;Programming profession;Text categorization;Workstations;Scalability","","","","17","","17","","26 Jan 2010","","","IEEE","IEEE Conferences"
"GCN Inference Acceleration using High-Level Synthesis","Y. C. Lin; B. Zhang; V. Prasanna","University of Southern California,Los Angeles,California; University of Southern California,Los Angeles,California; University of Southern California,Los Angeles,California","2021 IEEE High Performance Extreme Computing Conference (HPEC)","1 Dec 2021","2021","","","1","6","GCN (Graph Convolutional Network) has become a promising solution for many applications, such as recommendation systems, social data mining, etc. Many of these applications requires low latency GCN inference.In this paper, we provide a case study of a GCN inference acceleration on FPGA. We explore high-level synthesis programming model to achieve low-latency inference. First, we propose a partition-centric mapping strategy to map the execution tasks of GCN onto FPGA to exploit data reuse, which reduces external memory access overhead. Second, we provide HLS-based kernel design with improved memory performance and achieve massive data parallelism. Third, we perform design space exploration to facilitate feasible pre-placement which avoids potential Place-and-Route (PnR) failures. We evaluate our design on a state-of-the-art FPGA platform using three commonly used datasets: Reddit, Yelp and Amazon-2M. We compare our design with two state-of-the-art libraries PyTorch-Geometric (PyG) and Deep Graph Library (DGL) running on high-end CPU and GPU by evaluating their latency and energy efficiency to perform full-batch GCN inference on a two-layer Vanilla-GCN model. Compared with PyG CPU version, our design reduces the latency by 59.95× and is 96.22× more energy efficient on the average. Compared with DGL, our design achieves 2.9 × –6.4× speedup and is 5.87× more energy efficient compared with the CPU version. Compared with the DGL GPU version, although the latency of our design is 1.67 × –2.5× that of DGL GPU, our design is 1.8× more energy efficient.","2643-1971","978-1-6654-2369-4","10.1109/HPEC49654.2021.9622801","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622801","","Social networking (online);Graphics processing units;Programming;Energy efficiency;Libraries;Space exploration;Low latency communication","","","","","","19","","1 Dec 2021","","","IEEE","IEEE Conferences"
"Network-on-Chip Design for Heterogeneous Multiprocessor System-on-Chip","B. Phanibhushana; S. Kundu","Dept. of Electr. & Comput. Eng., Univ. of Massachusetts Amherst, Amherst, MA, USA; Dept. of Electr. & Comput. Eng., Univ. of Massachusetts Amherst, Amherst, MA, USA","2014 IEEE Computer Society Annual Symposium on VLSI","22 Sep 2014","2014","","","486","491","With burgeoning growth of mobile systems, multiprocessor System-on-Chip (MPSoC) connected via Network-on-Chip (NoC) has become ubiquitous. A typical MPSoC in mobile applications consists of multiple CPU cores of varying capabilities, GPU cores, DSP cores, and crypto accelerators and such cores differ widely in their physical size and their bandwidth requirements. Traditional mesh based NoC systems work well for regular structures, but do not map well to heterogeneous MPSoCs. In MPSoC programming model, an application consists of tasks, that represent a unit of work on a core which can be executed asynchronously. The communication between tasks is represented in the form of a directed acyclic graph. The temporal burstness of data which arise from programming model provide opportunity for multiplexing communication between cores, which may be advantageous in reducing network size. Often a task graph needs to meet a real-time deadline. The actual execution time may vary based on the application data. The uncertainty in the execution time may be modeled by a statistical distribution, which further complicates the NoC design. In this paper, we present a synthesis method for hierarchical design of NoC for a given task graph system deadline, that optimizes for router area. A 2-phase design flow is proposed, which consists of topology generation and statistical analysis in an iterative loop. We adopt proportion of Monte-Carlo test cases that meet the deadline as a metric for goodness. The proposed solution is compared against static design approach and simulated annealing (SA) based network generation. On an average, a performance benefit of 10% over SA, 16% over standard mesh and 30% over static design was obtained and a total router area benefit of 59% over SA, 48% over mesh and 55% over static design was observed.","2159-3477","978-1-4799-3765-3","10.1109/ISVLSI.2014.96","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6903411","Network-on-chip;Realtime systems;Statistical design;Kernighan-Lin","Partitioning algorithms;Bandwidth;Topology;System-on-chip;Monte Carlo methods;Algorithm design and analysis;Cost function","integrated circuit design;Monte Carlo methods;multiprocessing systems;network-on-chip;statistical analysis","network-on-chip design;heterogeneous multiprocessor system-on-chip;hierarchical design;NoC;task graph system deadline;router area;2-phase design flow;topology generation;statistical analysis;iterative loop;Monte-Carlo test cases","","3","","24","","22 Sep 2014","","","IEEE","IEEE Conferences"
"FCUDA: Enabling efficient compilation of CUDA kernels onto FPGAs","A. Papakonstantinou; K. Gururaj; J. A. Stratton; D. Chen; J. Cong; W. W. Hwu","Electrical & Computer Eng. Dept., University of Illinois, Urbana-Champaign, USA; Computer Science Dept., University of California, Los-Angeles, USA; Electrical & Computer Eng. Dept., University of Illinois, Urbana-Champaign, USA; Electrical & Computer Eng. Dept., University of Illinois, Urbana-Champaign, USA; Computer Science Dept., University of California, Los-Angeles, USA; Electrical & Computer Eng. Dept., University of Illinois, Urbana-Champaign, USA","2009 IEEE 7th Symposium on Application Specific Processors","28 Aug 2009","2009","","","35","42","As growing power dissipation and thermal effects disrupted the rising clock frequency trend and threatened to annul Moore's law, the computing industry has switched its route to higher performance through parallel processing. The rise of multicore systems in all domains of computing has opened the door to heterogeneous multiprocessor, where processors of different compute characteristics can be combined to effectively boost the performance per watt of different application kernels. GPUs and FPGAs are becoming very popular in PC-based heterogeneous systems for speeding up compute intensive kernels of scientific, imaging and simulation applications. GPUs can execute hundreds of concurrent threads, while FPGAs provide customized concurrency for highly parallel kernels. However, exploiting the parallelism available in these applications is currently not a push-button task. Often the programmer has to expose the application's fine and coarse grained parallelism by using special APIs. CUDA is such a parallel computing API that is driven by the GPU industry and is gaining significant popularity. In this work, we adapt the CUDA programming model into a new FPGA design flow called FCUDA, which efficiently maps the coarse and fine grained parallelism exposed in CUDA onto the reconfigurable fabric. Our CUDA-to-FPGA flow employs autopilot, an advanced high level synthesis tool which enables high abstraction FPGA programming. FCUDA is based on a source-to-source compilation that transforms the SPMD CUDA thread blocks into parallel C code for autopilot. We describe the details of our CUDA-to-FPGA flow and demonstrate the highly competitive performance of the resulting customized FPGA multi-core accelerators. To the best of our knowledge, this is the first CUDA-to-FPGA flow to demonstrate the applicability and potential advantage of using the CUDA programming model for high-performance computing in FPGAs.","","978-1-4244-4939-2","10.1109/SASP.2009.5226333","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5226333","","Kernel;Field programmable gate arrays;Parallel processing;Concurrent computing;Computer industry;Yarn;Power dissipation;Clocks;Frequency;Moore's Law","application program interfaces;field programmable gate arrays;multiprocessing systems;parallel architectures","CUDA kernel;FPGA programming;field programmable gate array;power dissipation;clock frequency;Moores law;computing industry;parallel processing;multicore system;multiprocessor system;performance per watt boosting;application program interface;compute unified device architecture;graphics processing unit","","82","1","23","","28 Aug 2009","","","IEEE","IEEE Conferences"
"Implementing Performance Portable Graph Algorithms Using Task-Based Execution","Ü. V. Çatalyürek",Georgia Institute of Technology,"2021 IEEE/ACM 11th Workshop on Irregular Applications: Architectures and Algorithms (IA3)","28 Dec 2021","2021","","","1","1","Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. Designing flexible graph kernels that can run well on various platforms is a crucial research problem due to the frequent usage of graphs for modeling data and recent architectural advances and variety. In this talk, I will present our recent graph processing model and framework, PGAbB, for modern shared-memory heterogeneous platforms. PGAbB implements a block-based programming model. This allows a user to express a graph algorithm using functors that operate on an ordered list of blocks (subgraphs). Our framework deploys these computations to all available resources in a heterogeneous architecture. We will demonstrate that one can implement a diverse set of graph algorithms in our framework, and task-based execution enables graph computations even on large graphs that do not fit in GPU device memory. Our experimental results show that PGAbB achieves competitive or superior performance compared to hand-optimized implementations or existing state-of-the-art graph computing frameworks.","2767-942X","978-1-6654-1126-4","10.1109/IA354616.2021.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9653075","","","","","","","","","","28 Dec 2021","","","IEEE","IEEE Conferences"
"High Performance Matrix Multiplication on General Purpose Graphics Processing Units","F. Wu; M. Cabral; J. Brazelton","Comput. Sci. Dept., Tuskegee Univ., Tuskegee, AL, USA; Comput. Sci. Dept., Tuskegee Univ., Tuskegee, AL, USA; Comput. Sci. Dept., Tuskegee Univ., Tuskegee, AL, USA","2010 International Conference on Computational Intelligence and Software Engineering","30 Dec 2010","2010","","","1","4","In recent years, there has been significant interest from both academia and industry in applying commodity graphics processing units (GPUs) toward general computing problems. The nVidia CUDA programming model provides a straightforward means of describing inherently parallel computations. In this paper, we present our GPU-based matrix multiplication with high performance on General Purpose Graphics Processing Unit (GPGPUs). We implemented our algorithm using nVidia CUDA API and compared its performance with an optimized CPU-implementation on a high-end AMD Opteron Dual Core CPU. Our experimental results show that a significant performance improvement over CPU-based algorithm and the maximum observed speedups are about 100 times.","","978-1-4244-5391-7","10.1109/CISE.2010.5677044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5677044","","Graphics processing unit;Kernel;Instruction sets;Computer architecture;Central Processing Unit;Programming","coprocessors;matrix multiplication","matrix multiplication;general purpose graphics processing units;nVidia CUDA programming;parallel computations;AMD Opteron Dual Core CPU","","","","5","","30 Dec 2010","","","IEEE","IEEE Conferences"
"Cellular Neural Networks for FPGAs with OpenCL","F. Richter-Gottfried; D. Fey",NA; NA,"CNNA 2016; 15th International Workshop on Cellular Nanoscale Networks and their Applications","23 Jan 2017","2016","","","1","2","Cellular Neural Networks (CNNs) are an inherently parallel computational model for multiple applications, and they are especially appropriate for image processing tasks. Besides of implementing them with analogue electronic circuits, they can be simulated on digital processor architectures like CPUs and GPUs, with the drawback of limited parallelism. FPGAs offer a fine-grained parallel execution with low power consumption and are thus attractive for embedded systems like smart cameras, for which it is not possible to use a full-featured CPU or GPU with tens or hundrets of watts. The drawback of implementing CNNs with FPGAs, to profit from the high performance-to-power ratio, is the time-consuming design process with conventional hardware descriptions languages. High-level-synthesis, e.g., from OpenCL, eases the process of generating CNNs in FPGAs. By using the OpenCL programming model, the programmer can explicitly express the parallel nature of CNNs in a platform-independent way. To investigate its applicability to CNNs, we compare the execution of an unmodified OpenCL kernel on a recent CPU with an FPGA design generated with Altera's SDK for OpenCL. The results show, that though the CPU is faster, the FPGA solution performs better in terms of energy efficiency and fits for smart camera systems.","","978-3-8007-4252-3","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7827967","","","","","","","","","","23 Jan 2017","","","VDE","VDE Conferences"
"Gemma in April: A matrix-like parallel programming architecture on OpenCL","T. Wu; D. Wu; Y. Wang; X. Zhang; H. Luo; N. Xu; H. Yang","Department of Electronic Engineering, TNList, Tsinghua University; Department of Electronic Engineering, TNList, Tsinghua University; Department of Electronic Engineering, TNList, Tsinghua University; Department of Electronic Engineering, TNList, Tsinghua University; Department of Electronic Engineering, TNList, Tsinghua University; Hardware Computing Group, Microsoft Research Asia; Department of Electronic Engineering, TNList, Tsinghua University","2011 Design, Automation & Test in Europe","5 May 2011","2011","","","1","6","Nowadays, Graphics Processing Unit (GPU), as a kind of massive parallel processor, has been widely used in general purposed computing tasks. Although there have been mature development tools, it is not a trivial task for programmers to write GPU programs. Based on this consideration, we propose a novel parallel computing architecture. The architecture includes a parallel programming model, named Gemma, and a programming framework, named April. Gemma is based on generalized matrix operations, and helps to alleviate the difficulty of describing parallel algorithms. April is a high-level framework that can compile and execute tasks described in Gemma with OpenCL. In particular, April can automatically 1) choose the best parallel algorithm and mapping scheme, and generate OpenCL kernels, 2) schedule Gemma tasks based on execution costs such as data storing and transferring. Our experimental results show that with competitive performance, April considerably reduces the programs' code length compared with OpenCL.","1558-1101","978-3-9810801-8-6","10.1109/DATE.2011.5763119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5763119","","Graphics processing unit;Computer architecture;Sparse matrices;Computational modeling;Kernel;Parallel programming","computer graphic equipment;coprocessors;parallel programming;programming languages","matrix-like parallel programming architecture;graphics processing unit;parallel computing architecture;Gemma;April;parallel algorithms;OpenCL kernels;data storing;data transferring;open computing language","","","","11","","5 May 2011","","","IEEE","IEEE Conferences"
"Evaluating Performance and Portability of a core bioinformatics kernel on multiple vendor GPUs","M. Haseeb; N. Ding; J. Deslippe; M. Awan","Florida International University,Miami,USA; Lawrence Berkeley National Laboratory,Berkeley,USA; Lawrence Berkeley National Laboratory,Berkeley,USA; Lawrence Berkeley National Laboratory,Berkeley,USA","2021 International Workshop on Performance, Portability and Productivity in HPC (P3HPC)","28 Dec 2021","2021","","","68","78","Traditional scientific simulations have for quite some time, dominated the workloads of high-performance computing infrastructures across the world. With recent advancement in data generation capabilities of systems biology equipment, a rise in bioinformatics workloads has been observed. Bioinformatics applications deploy algorithmic motifs that use unique memory access patterns and rely heavily on integer-only computations. These applications place unique requirements on modern programming environments as well as GPU accelerators which are becoming an integral part of next generation of supercomputers. In this paper, we evaluate the performance and code portability of a core bioinformatics kernel that uses dynamic programming method for performing DNA and protein sequence alignments in several bioinformatics software pipelines. Our study evaluates the performance of a GPU accelerated sequence alignment algorithm across multiple vendor GPUs and programming models. We use a highly optimized adaptation of sequence alignment kernel and find the most productive way of porting it across multiple vendor GPUs and then assess its performance portability using Pennycook's method. Methods used in this paper and the insights drawn from those can be extended to a large number of integer-heavy scientific kernels and may aid in future accelerator design and design of programming model requirements.","","978-1-6654-2439-4","10.1109/P3HPC54578.2021.00010","U.S. Department of Energy(grant numbers:17-SC-20-SC); National Nuclear Security Administration; Oak Ridge National Laboratory; Office of Science of the U.S. Department of Energy(grant numbers:DE-AC05-000R22725); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9652848","Performance;Portability;GPUs;Bioinformatics;DNA;Protein;Sequence Alignment","Performance evaluation;Codes;Biological system modeling;Graphics processing units;Computer architecture;Programming;Supercomputers","","","","","","39","","28 Dec 2021","","","IEEE","IEEE Conferences"
"An open-source solution to performance portability for Summit and Sierra supercomputers","G. T. Bercea; A. Bataev; A. E. Eichenberger; C. Bertolli; J. K. O'Brien",NA; NA; NA; NA; NA,"IBM Journal of Research and Development","13 May 2020","2020","64","3/4","12:1","12:23","Programming models that use a higher level of abstraction to express parallelism can target both CPUs and any attached devices, alleviating the maintainability and portability concerns facing today's heterogenous systems. This article describes the design, implementation, and delivery of a compliant OpenMP device offloading implementation for IBM-NVIDIA heterogeneous servers composing the Summit and Sierra supercomputers in the mainline open-source Clang/LLVM compiler and OpenMP runtime projects. From a performance perspective, reconciling the GPU programming model, best suited for massively parallel workloads, with the generality of the OpenMP model was a significant challenge. To achieve both high performance and full portability, we map high-level programming patterns to fine-tuned code generation schemes and customized runtimes that preserve the OpenMP semantics. In the compiler, we implement a low-overhead single-program multiple-data scheme that leverages the GPU native execution model and a fallback scheme to support the generality of OpenMP. Modular design enables the implementation to be extended with new schemes for frequently occurring patterns. Our implementation relies on key optimizations: sharing data among threads, leveraging unified memory, aggressive inlining of runtime calls, memory coalescing, and runtime simplification. We show that for commonly used patterns, performance on the Summit and Sierra GPUs matches that of hand-written native CUDA code.","0018-8646","","10.1147/JRD.2019.2955944","CORAL(grant numbers:B604142); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8928619","","Programming;Graphics processing units;Instruction sets;Runtime;Computational modeling;Open source software;Performance evaluation","","","","","","39","IBM","9 Dec 2019","","","IBM","IBM Journals"
"Designing APU Oriented Scientific Computing Applications in OpenCL","M. Doerksen; S. Solomon; P. Thulasiraman","Dept. of Comput. Sci., Univ. of Manitoba, Winnipeg, MB, Canada; Dept. of Comput. Sci., Univ. of Manitoba, Winnipeg, MB, Canada; Dept. of Comput. Sci., Univ. of Manitoba, Winnipeg, MB, Canada","2011 IEEE International Conference on High Performance Computing and Communications","31 Oct 2011","2011","","","587","592","The future of high performance computing is moving towards exa-scale computing. Graphical Processing Units (GPUs) have demonstrated their capabilities beyond graphics rendering or general purpose computing and are well suited for data intensive applications. However, the communication bottleneck for data transfer between the GPU and CPU has led to the design of AMD's Accelerated Processing Unit (APU) which combines the CPU and GPU on a single chip. This new architecture poses new challenges: algorithms must be redesigned to take advantage of this architecture and programming models differ between vendors, hindering the portability of algorithms across heterogeneous platforms. Recently, OpenCL has been regarded as the standard programming model for heterogeneous platforms. With the future of general purpose computing moving towards APUs, in this paper, we study the design and implementation of two problems: 0-1 knapsack and Gaussian Elimination in OpenCL. This pair of algorithms showcases similar synchronization behaviors, enabling a more direct comparison. We discuss the design and performance of these algorithms using OpenCL.","","978-1-4577-1564-8","10.1109/HPCC.2011.83","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6063044","","Graphics processing unit;Instruction sets;Synchronization;Central Processing Unit;Algorithm design and analysis;Computer architecture;Equations","computer graphic equipment;coprocessors;parallel algorithms;programming languages","APU oriented scientific computing application;accelerated processing unit;high performance computing;OpenCL;exascale computing;graphical processing unit;graphics rendering;general purpose computing;0-1 knapsack problem;Gaussian elimination problem;synchronization behavior;open computing language","","9","","12","","31 Oct 2011","","","IEEE","IEEE Conferences"
"Cambricon-G: A Polyvalent Energy-Efficient Accelerator for Dynamic Graph Neural Networks","X. Song; T. Zhi; Z. Fan; Z. Zhang; X. Zeng; W. Li; X. Hu; Z. Du; Q. Guo; Y. Chen","State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","22 Dec 2021","2022","41","1","116","128","Graph neural networks (GNNs), which extend traditional neural networks for processing graph-structured data, have been widely used in many fields. The GNN computation mainly consists of the <italic>edge processing</italic> to generate messages by combining the edge/vertex features and the <italic>vertex processing</italic> to update the vertex features with aggregated messages. In addition to nontrivial vector operations in the edge processing, huge random accesses and neural network operations in the vertex processing, the graph topology of GNNs may also vary during the computation (i.e., dynamic GNNs). The above characteristics pose significant challenges on existing architectures. In this article, we propose a novel accelerator named CAMBRICON-G for efficient processing of both dynamic and static GNNs. The key of CAMBRICON-G is to abstract the irregular computation of a broad range of GNN variants to the process of regularly tiled <italic>adjacent cuboid</italic> (which extends the traditional adjacent matrix of graph by adding the dimension of vertex features). The intuition is that the adjacent cuboid facilitates exploitation of both data locality and parallelism by offering <italic>multidimensional multilevel tiling</italic> (including spatial and temporal tiling) opportunities. To perform the <italic>multidimensional spatial tiling</italic>, the CAMBRICON-G architecture mainly consists of the cuboid engine (CE) and hybrid on-chip memory. The CE has multiple vertex processing units (VPUs) working in a coordinated manner to efficiently process the sparse data and dynamically update the graph topology with dedicated instructions. The hybrid on-chip memory contains the topology-aware cache and multiple scratchpad memory to reduce off-chip memory access. To perform the <italic>multidimensional temporal tiling</italic>, an easy-to-use programming model is provided to flexibly explore different tiling options for large graphs. Experimental results show that compared against Nvidia P100 GPU, the performance and energy efficiency can be improved by <inline-formula> <tex-math notation=""LaTeX"">$7.14\times $ </tex-math></inline-formula> and <inline-formula> <tex-math notation=""LaTeX"">$20.18\times $ </tex-math></inline-formula>, respectively, on various GNNs, which validates both the versatility and energy efficiency of CAMBRICON-G.","1937-4151","","10.1109/TCAD.2021.3052138","National Key Research and Development Program of China(grant numbers:2017YFA0700900,2017YFA0700902,2017YFA0700901); NSF of China(grant numbers:61925208,61732007,61732002,61702478,61906179,62002338,61702459,U19B2019,U20A20227); Beijing Natural Science Foundation(grant numbers:JQ18013); Key Research Projects in Frontier Science of Chinese Academy of Sciences(grant numbers:QYZDB-SSW-JSC001); Strategic Priority Research Program of Chinese Academy of Science(grant numbers:XDB32050200,XDC05010300,XDC08040102); Beijing Academy of Artificial Intelligence (BAAI) and Beijing Nova Program of Science and Technology(grant numbers:Z191100001119093); Science and Technology Planning Project of Guangdong Province(grant numbers:2019B090909005); Youth Innovation Promotion Association CAS and Xplore Prize; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9326339","Accelerator;architecture;graph neural networks (GNNs)","Hardware;Programming;Topology;System-on-chip;Graphics processing units;Convolution;Engines","","","","","","32","IEEE","18 Jan 2021","","","IEEE","IEEE Journals"
"HyGCN: A GCN Accelerator with Hybrid Architecture","M. Yan; L. Deng; X. Hu; L. Liang; Y. Feng; X. Ye; Z. Zhang; D. Fan; Y. Xie","Chinese Academy of Sciences; University of California, Santa Barbara; University of California, Santa Barbara; University of California, Santa Barbara; Chinese Academy of Sciences; Chinese Academy of Sciences; Chinese Academy of Sciences; Chinese Academy of Sciences; University of California, Santa Barbara","2020 IEEE International Symposium on High Performance Computer Architecture (HPCA)","16 Apr 2020","2020","","","15","29","Inspired by the great success of neural networks, graph convolutional neural networks (GCNs) are proposed to analyze graph data. GCNs mainly include two phases with distinct execution patterns. The Aggregation phase, behaves as graph processing, showing a dynamic and irregular execution pattern. The Combination phase, acts more like the neural networks, presenting a static and regular execution pattern. The hybrid execution patterns of GCNs require a design that alleviates irregularity and exploits regularity. Moreover, to achieve higher performance and energy efficiency, the design needs to leverage the high intra-vertex parallelism in Aggregation phase, the highly reusable inter-vertex data in Combination phase, and the opportunity to fuse phase-by-phase execution introduced by the new features of GCNs. However, existing architectures fail to address these demands. In this work, we first characterize the hybrid execution patterns of GCNs on Intel Xeon CPU. Guided by the characterization, we design a GCN accelerator, HyGCN, using a hybrid architecture to efficiently perform GCNs. Specifically, first, we build a new programming model to exploit the fine-grained parallelism for our hardware design. Second, we propose a hardware design with two efficient processing engines to alleviate the irregularity of Aggregation phase and leverage the regularity of Combination phase. Besides, these engines can exploit various parallelism and reuse highly reusable data efficiently. Third, we optimize the overall system via inter-engine pipeline for inter-phase fusion and priority-based off-chip memory access coordination to improve off-chip bandwidth utilization. Compared to the state-of-the-art software framework running on Intel Xeon CPU and NVIDIA V100 GPU, our work achieves on average 1509× speedup with 2500× energy reduction and average 6.5× speedup with 10× energy reduction, respectively.","2378-203X","978-1-7281-6149-5","10.1109/HPCA47549.2020.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9065592","Hardware Accelerator, Graph Convolution Neural Network, Graph Processing, Hybrid Execution Pattern","Computer architecture;Neural networks;Engines;Parallel processing;Aggregates;Fuses;Hardware","convolutional neural nets;graph theory;graphics processing units;microprocessor chips;multiprocessing systems;parallel architectures;parallel processing;power aware computing","hybrid execution patterns;GCNs;energy efficiency;high intra-vertex parallelism;Aggregation phase;phase-by-phase execution;Intel Xeon CPU;GCN accelerator;HyGCN;hybrid architecture;hardware design;inter-phase fusion;priority-based off-chip memory access coordination;graph convolutional neural networks;graph data;graph processing;inter-vertex data;off-chip bandwidth utilization;software framework","","38","","46","","16 Apr 2020","","","IEEE","IEEE Conferences"
"CoSMo: Intent-based composition of shader modules","G. Haaser; H. Steinlechner; M. May; M. Schwärzler; S. Maierhofer; R. Tobler","VRVis Research Center, Donau-City-Strasse 1, Vienna, Austria; VRVis Research Center, Donau-City-Strasse 1, Vienna, Austria; VRVis Research Center, Donau-City-Strasse 1, Vienna, Austria; VRVis Research Center, Donau-City-Strasse 1, Vienna, Austria; VRVis Research Center, Donau-City-Strasse 1, Vienna, Austria; VRVis Research Center, Donau-City-Strasse 1, Vienna, Austria","2014 International Conference on Computer Graphics Theory and Applications (GRAPP)","12 Oct 2015","2014","","","1","11","We propose a novel shader programming model which operates on intent-oriented shader modules instead of specific programs for dedicated GPU rasterization pipeline stages. In constrast to existing pipeline shader frameworks, our system exposes a radically simplified pipeline, which we purposefully aligned with our basic intuition of shaders as per-primitive and per-pixel operations and compositions thereof. This simplicity lends itself to structure modules purely based on their intent, instead of dealing with structure enforced by specific versions of graphics APIs. Consequently, this offers great flexibility when it comes to reusing and combining modules with completely different semantics, or when targeting different graphics APIs. The simplicity and uniformity of our system also motivates automatic parameterization and simplification of shader programs as well as interesting interactive shader development and management techniques.","","978-9-8975-8078-9","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7296051","Shader;Composition;Rendering;Language;Embedded","Semantics;Pipelines;Programming;Lighting;Rendering (computer graphics);Synthesizers;Surface treatment","","","","","","22","","12 Oct 2015","","","IEEE","IEEE Conferences"
"A Hybrid Cache HW/SW Stack for Optimizing Neural Network Runtime, Power and Endurance","W. A. Simon; A. Levisse; M. Zapater; D. Atienza","Embedded Systems Laboratory (ESL), Swiss Federal Institute of Technology Lausanne (EPFL); Embedded Systems Laboratory (ESL), Swiss Federal Institute of Technology Lausanne (EPFL); University of Applied Sciences Western Switzerland (HEIG-VD / HES-SO); Embedded Systems Laboratory (ESL), Swiss Federal Institute of Technology Lausanne (EPFL)","2020 IFIP/IEEE 28th International Conference on Very Large Scale Integration (VLSI-SOC)","10 Feb 2021","2020","","","94","99","Hybrid caches consisting of both SRAM and emerging Non-Volatile Random Access Memory (eNVRAM) bitcells increase cache capacity and reduce power consumption by taking advantage of eNVRAM's small area footprint and low leakage energy. However, they also inherit eNVRAM's drawbacks, including long write latency and limited endurance. To mitigate these drawbacks, many works propose heuristic strategies to allocate memory blocks into SRAM or eNVRAM arrays at runtime based on block content or access pattern. In contrast, this work presents a HW/SW Stack for Hybrid Caches (SHyCache), consisting of a hybrid cache architecture and supporting programming model, reminiscent of those that enable GP-GPU acceleration, in which application variables can be allocated explicitly to the eNVRAM cache, eliminating the need for heuristics and reducing cache access time, power consumption, and area overhead while maintaining maximal cache utilization efficiency and ease of programming. SHyCache improves performance for applications such as neural networks, which contain large numbers of invariant weight values with high read/write access ratios that can be explicitly allocated to the eNVRAM array. We simulate SHyCache on the gem5-X architectural simulator and demonstrate its utility by benchmarking a range of cache hierarchy variations using three neural networks, namely, Inception v4, ResNet-50, and SqueezeNet 1.0. We demonstrate a design space that can be exploited to optimize performance, power consumption, or endurance, depending on the expected use case of the architecture, while demonstrating maximum performance gains of 1.7 /1.4/1.3x and power consumption reductions of 5.1/5.2/5.4x, for Inception/ResNet/SqueezeNet, respectively.","2324-8440","978-1-7281-5409-1","10.1109/VLSI-SOC46417.2020.9344087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9344087","eNVRAM;STT-MRAM;hybrid caches;neural networks;low-power systems","Power demand;Runtime;Random access memory;Programming;Benchmark testing;Hybrid power systems;Resource management","","","","","","26","","10 Feb 2021","","","IEEE","IEEE Conferences"
"VSIPL++ Acceleration Using Commodity Graphics Processors","D. Campbell","Georgia Tech Research Institute, Smyrna, GA","2006 HPCMP Users Group Conference (HPCMP-UGC'06)","19 Mar 2007","2006","","","315","320","The High Performance Embedded Computing Software Initiative (HPEC-SI) is developing a unified software framework for computation and communication for high performance signal processing tasks on parallel computers. The goal of the program is to address the high cost of software in Department of Defense (DoD) systems by improving the portability and productivity of signal processing application development, while simultaneously improving performance compared to current practices. The Vector, Signal, and Image Processing Library (VSIPL) is a portable application programming interface (API) that is widely used for embedded DoD signal processing systems. One portion of the HPEC-SI effort includes the development of C++ extensions for the existing VSIPL standard, called VSIPL++. Commodity graphics processing units (GPUs) are application-specific processors that implement a standardized three-dimensional graphics-rendering pipeline, and provide significant floating-point processing capacity at much lower cost, power consumption, and physical space compared to general-purpose processors. Recent changes in GPUs have increased programmability and flexibility in portions of the rendering pipeline, allowing non-graphics applications to exploit their computational capacity. Restrictions on the programming model, lack of appropriate tools, unusual performance behavior, and other factors make exploiting GPUs a costly, difficult, and time-consuming process for application developers. The embedded systems that VSIPL and VSIPL++ are commonly used on share several important characteristics with GPUs, making VSIPL++ well suited to abstract and exploit GPUs. This paper describes GPUVSIPL++, an implementation of portions of the VSIPL++ standard that exploits a GPU to accelerate computation beyond what is possible on a development workstation","","0-7695-2797-3","10.1109/HPCMP-UGC.2006.77","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4134073","","Acceleration;Graphics;Signal processing;Embedded computing;Software performance;Embedded software;Concurrent computing;High performance computing;Costs;Application software","application program interfaces;microprocessor chips","VSIPL++ acceleration;commodity graphics processors;unified software framework;high performance signal processing;parallel computers;portable application programming interface;3D graphics-rendering pipeline;floating-point processing;GPUVSIPL++","","2","","13","","19 Mar 2007","","","IEEE","IEEE Conferences"
"Benchmarking and Extending SYCL Hierarchical Parallelism","T. Deakin; S. McIntosh-Smith; A. Alpay; V. Heuveline","University of Bristol,Department of Computer Science,Bristol,UK; University of Bristol,Department of Computer Science,Bristol,UK; Universität Heidelberg,Engineering Mathematics and Computing Lab and Interdisciplinary Center for Scientific Computing,Heidelberg,Germany; Universität Heidelberg,Engineering Mathematics and Computing Lab and Interdisciplinary Center for Scientific Computing,Heidelberg,Germany","2021 IEEE/ACM International Workshop on Hierarchical Parallelism for Exascale Computing (HiPar)","24 Dec 2021","2021","","","10","19","SYCL is an open-standard, parallel programming model for programming heterogeneous devices from Khronos. It allows single-source programming of diverse attached devices in a cross-platform manner in modern C++. SYCL provides different layers of parallel abstractions, including Same Instruction Multiple Thread (SIMT) kernels, data-parallel loop concurrency and hierarchical parallelism. We discuss Scoped Parallelism as an extension to the existing Hierarchical Parallelism in SYCL, and highlight the advantages and disadvantages of these models from the perspective of the programmer and an implementer of SYCL. In this paper, we compare writing benchmark programs using SIMT kernel, hierarchical parallelism and scoped parallelism paradigms, and present results running on a high-performance CPU and GPU.","","978-1-6654-1132-5","10.1109/HiPar54615.2021.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9654235","","Concurrent computing;Parallel programming;Exascale computing;Conferences;Graphics processing units;C++ languages;Parallel processing","","","","","","8","","24 Dec 2021","","","IEEE","IEEE Conferences"
"CPUs and GPUs: Who Owns the Future?","E. R. Altman",ealtman@us.ibm.com,"IEEE Micro","17 Oct 2011","2011","31","5","2","3","This column addresses issues facing CPUs, GPUs, and how to program them and other computing devices.","1937-4143","","10.1109/MM.2011.84","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6045683","CPU;GPU;performance;application-specific integrated circuit;field-programmable gate array;programming model;productivity","","","","","1","","","IEEE","17 Oct 2011","","","IEEE","IEEE Magazines"
"A nodal discontinuous Galerkin method for reverse-time migration on GPU clusters","A. Modave; A. St-Cyr; W. A. Mulder; T. Warburton",NA; NA; NA; NA,"Geophysical Journal International","18 Jan 2018","2015","203","2","1419","1435","Improving both accuracy and computational performance of numerical tools is a major challenge for seismic imaging and generally requires specialized implementations to make full use of modern parallel architectures. We present a computational strategy for reverse-time migration (RTM) with accelerator-aided clusters. A new imaging condition computed from the pressure and velocity fields is introduced. The model solver is based on a high-order discontinuous Galerkin time-domain (DGTD) method for the pressure–velocity system with unstructured meshes and multirate local time stepping. We adopted the MPI+X approach for distributed programming where X is a threaded programming model. In this work we chose OCCA, a unified framework that makes use of major multithreading languages (e.g. CUDA and OpenCL) and offers the flexibility to run on several hardware architectures. DGTD schemes are suitable for efficient computations with accelerators thanks to localized element-to-element coupling and the dense algebraic operations required for each element. Moreover, compared to high-order finite-difference schemes, the thin halo inherent to DGTD method reduces the amount of data to be exchanged between MPI processes and storage requirements for RTM procedures. The amount of data to be recorded during simulation is reduced by storing only boundary values in memory rather than on disk and recreating the forward wavefields. Computational results are presented that indicate that these methods are strong scalable up to at least 32 GPUs for a three-dimensional RTM case.","1365-246X","","10.1093/gji/ggv380","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8188177","Image processing;Numerical solutions;Computational seismology","","","","","1","","","","18 Jan 2018","","","OUP","OUP Journals"
"Keynote 1 — It's about time","E. A. Lee",U. C. Berkeley,"2014 International Conference on ReConFigurable Computing and FPGAs (ReConFig14)","9 Feb 2015","2014","","","1","1","Summary form only given. Cyber-physical systems are integrations of computation, communication networks, and physical dynamics. Although time plays a central role in the physical world, all widely used software abstractions lack temporal semantics. The notion of correct execution of a program written in every widely-used programming language today does not depend on the temporal behavior of the program. But temporal behavior matters in almost all systems. Even in systems with no particular real-time requirements, timing of programs is relevant to the value delivered by programs, and in the case of concurrent programs, also affects the functionality. In cyber-physical systems, temporal behavior affects not just the value delivered by a system but also its correctness. In this talk, I will argue that time can and must become part of the semantics of programs for a large class of applications. To illustrate that this is both practical and useful, we will describe two recent efforts at Berkeley in the design and implementation of timing-centric software systems. On the implementation side, I will describe PRET machines, which redefine the instruction-set architecture (ISA) of a microprocessor to include temporal semantics. Such machines can be used in high-confidence and safety-critical systems, in energy-constrained systems, in mixed-criticality systems, and as a Real-Time Unit (RTU) that cooperates with a general-purpose processor to provide real-time services, in a manner similar to how a GPU provides graphics services. On the design side, I will briefly describe PTIDES, a programming model for distributed real-time systems.","2325-6532","978-1-4799-5944-0","10.1109/ReConFig.2014.7032479","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7032479","","","instruction sets;programming language semantics","distributed real time systems;programming model;PTIDES;RTU;real time unit;mixed criticality systems;energy constrained systems;safety critical systems;microprocessor;ISA;instruction set architecture;timing centric software systems;Berkeley;concurrent programs;temporal behavior;programming language;program written;software abstractions lack temporal semantics;physical dynamics;communication networks;cyber physical systems","","","","","","9 Feb 2015","","","IEEE","IEEE Conferences"
"[Front matter]","",,"International Symposium on Code Generation and Optimization (CGO 2011)","5 May 2011","2011","","","i","ii","The following topics are dealt with: polyhedral compilation; machine learning; software-hardware co-design; DSP; data parallel heterogeneous system; GPU programming model; source-to-source compiler optimisation; safety-critical real-time system; WCET-aware C compiler; high-level language; low level code optimization; performance asymmetric multicore processors; tagless instruction cache; software transactional memory optimization; multiprocessor chip; vapor SIMD; on-chip cache hierarchy aware tile scheduling; data locality; NoC based multicore; embedded language; virtual machine; Java JIT compiler; highly scalable distributed dataflow analysis; and flow sensitive pointer analysis.","","978-1-61284-357-5","10.1109/CGO.2011.5764642","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5764642","","","cache storage;data flow analysis;hardware-software codesign;Java;multiprocessing systems;network-on-chip;optimising compilers;parallel processing;safety-critical software;virtual machines","polyhedral compilation;machine learning;software-hardware co-design;DSP;data parallel heterogeneous system;GPU programming model;source-to-source compiler optimisation;safety-critical real-time system;WCET-aware C compiler;high-level language;low level code optimization;performance asymmetric multicore processors;tagless instruction cache;software transactional memory optimization;multiprocessor chip;vapor SIMD;on-chip cache hierarchy aware tile scheduling;data locality;NoC based multicore;embedded language;virtual machine;Java JIT compiler;highly scalable distributed dataflow analysis;flow sensitive pointer analysis","","","","","","5 May 2011","","","IEEE","IEEE Conferences"
"[Title page i]","",,"2011 11th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","11 Jul 2011","2011","","","i","i","The following topics are dealt with: cluster computing; cloud computing; grid computing; virtual machines; GPU-based computing; programming models; runtime systems; volunteer computing; distributed systems; resource scheduling; data streaming; caching memory; shared memory; data-driven computing; fault tolerance; checkpointing; communication management; network management; distributed hash tables; I/O systems; file systems; QoS; data intensive computing; MapReduce; security; social network; business workshop; industry workshop; and enterprise workshop.","","978-1-4577-0129-0","10.1109/CCGrid.2011.1","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5948665","","","cache storage;cloud computing;computer graphic equipment;coprocessors;cryptography;data analysis;distributed shared memory systems;fault tolerant computing;grid computing;pattern clustering;quality of service;resource allocation;social networking (online);telecommunication network management;virtual enterprises;virtual machines","cluster computing;cloud computing;grid computing;virtual machine;GPU-based computing;programming model;runtime system;volunteer computing;distributed system;resource scheduling;data streaming;caching memory;shared memory;data-driven computing;fault tolerance;checkpointing;communication management;network management;distributed hash tables;I/O system;QoS;data intensive computing;MapReduce;security;social network;business workshop;industry workshop;enterprise workshop;file system","","","","","","11 Jul 2011","","","IEEE","IEEE Conferences"
